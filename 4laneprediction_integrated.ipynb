{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4laneprediction_integrated.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl7SgLBuYP1L",
        "colab_type": "text"
      },
      "source": [
        "#4 Lane Prediction through live cameras\n",
        "Note:\n",
        "1. Here we used 4 videos as live feed rather than using 4 cameras since \n",
        "we were unable to get 4 cameras and connect it to a single PC.\n",
        "2. Our code not only works for 4 lanes but also works for N number of lanes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCcSjfWpacFs",
        "colab_type": "text"
      },
      "source": [
        "* Importing necessary Libraries and loading our model goes here.\n",
        "* We used YOLOModel for ambulance detection and VGG16 for traffic density prediction\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImLvX-eZYJtQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ac085ac8-531b-43ee-f5f1-1e35acae5421"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Dropout\n",
        "import struct\n",
        "from keras.layers import Conv2D\n",
        "from keras.models import Model\n",
        "from numpy import expand_dims\n",
        "from keras.models import load_model\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "from skimage import io\n",
        "from PIL import Image \n",
        "from keras.preprocessing import image\n",
        "from datetime import datetime\n",
        "import os\n",
        "import time\n",
        "from threading import Thread\n",
        "modelyolo = load_model('/content/drive/My Drive/YOLOModel.h5')   #loading YOLO Model\n",
        "\n",
        "model =VGG16(input_shape=(224,224,3),include_top=False,weights='imagenet') #initializing VGG16\n",
        "\n",
        "\n",
        "regularizer = tf.keras.regularizers.l2(0.01)\n",
        "#Adding regularizer to overcome Overfitting of the model\n",
        "for layer in model.layers:\n",
        "    for attr in ['kernel_regularizer']:\n",
        "        if hasattr(layer, attr):\n",
        "          setattr(layer, attr, regularizer)\n",
        "\n",
        "\n",
        "for layer in model.layers[:11]:\n",
        "  layer.trainable=False\n",
        "\n",
        "\n",
        "Model = Sequential()\n",
        "for layer in model.layers[:11]:\n",
        "  layer.trainable=True\n",
        "  Model.add(layer)\n",
        "c=0  \n",
        "for layer in model.layers[11:]:\n",
        "  Model.add(layer)\n",
        "  c+=1\n",
        "  if c%4==0:\n",
        "    Model.add(Dropout(0.3)) \n",
        "\n",
        "Model.add(GlobalAveragePooling2D())\n",
        "Model.add(Dense(units=4098,activation=\"relu\"))\n",
        "Model.add(Dense(units=4098,activation=\"relu\"))\n",
        "Model.add(Dense(units=3, activation=\"softmax\"))\n",
        "Model.load_weights('/content/drive/My Drive/Traffic_Densen(VGG)(1)new.h5')\n",
        "#loading weights(trained in another notebook) to the VGG16 model which we had defined above.  \n",
        "\n",
        "modelresnet =tf.keras.applications.ResNet101()\n",
        "#loading pretrained ResNet101 model"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3wzp-pCchcS",
        "colab_type": "text"
      },
      "source": [
        "* Functions required for Ambulance detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIA7eemrYmKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#functions required for V3\n",
        "from keras.preprocessing import image\n",
        "class BoundBox:\n",
        "\tdef __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "\t\tself.xmin = xmin\n",
        "\t\tself.ymin = ymin\n",
        "\t\tself.xmax = xmax\n",
        "\t\tself.ymax = ymax\n",
        "\t\tself.objness = objness\n",
        "\t\tself.classes = classes\n",
        "\t\tself.label = -1\n",
        "\t\tself.score = -1\n",
        " \n",
        "\tdef get_label(self):\n",
        "\t\tif self.label == -1:\n",
        "\t\t\tself.label = np.argmax(self.classes)\n",
        " \n",
        "\t\treturn self.label\n",
        " \n",
        "\tdef get_score(self):\n",
        "\t\tif self.score == -1:\n",
        "\t\t\tself.score = self.classes[self.get_label()]\n",
        " \n",
        "\t\treturn self.score\n",
        " \n",
        "def _sigmoid(x):\n",
        "\treturn 1. / (1. + np.exp(-x))\n",
        " \n",
        "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
        "\tgrid_h, grid_w = netout.shape[:2]\n",
        "\tnb_box = 3\n",
        "\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "\tnb_class = netout.shape[-1] - 5\n",
        "\tboxes = []\n",
        "\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        " \n",
        "\tfor i in range(grid_h*grid_w):\n",
        "\t\trow = i / grid_w\n",
        "\t\tcol = i % grid_w\n",
        "\t\tfor b in range(nb_box):\n",
        "\t\t\t# 4th element is objectness score\n",
        "\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n",
        "\t\t\tif(objectness.all() <= obj_thresh): continue\n",
        "\t\t\t# first 4 elements are x, y, w, and h\n",
        "\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n",
        "\t\t\tx = (col + x) / grid_w # center position, unit: image width\n",
        "\t\t\ty = (row + y) / grid_h # center position, unit: image height\n",
        "\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
        "\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
        "\t\t\t# last elements are class probabilities\n",
        "\t\t\tclasses = netout[int(row)][col][b][5:]\n",
        "\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "\t\t\tboxes.append(box)\n",
        "\treturn boxes\n",
        " \n",
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "\tnew_w, new_h = net_w, net_h\n",
        "\tfor i in range(len(boxes)):\n",
        "\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
        " \n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "\tx1, x2 = interval_a\n",
        "\tx3, x4 = interval_b\n",
        "\tif x3 < x1:\n",
        "\t\tif x4 < x1:\n",
        "\t\t\treturn 0\n",
        "\t\telse:\n",
        "\t\t\treturn min(x2,x4) - x1\n",
        "\telse:\n",
        "\t\tif x2 < x3:\n",
        "\t\t\t return 0\n",
        "\t\telse:\n",
        "\t\t\treturn min(x2,x4) - x3\n",
        " \n",
        "def bbox_iou(box1, box2):\n",
        "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "\tintersect = intersect_w * intersect_h\n",
        "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "\tunion = w1*h1 + w2*h2 - intersect\n",
        "\treturn float(intersect) / union\n",
        " \n",
        "def do_nms(boxes, nms_thresh):\n",
        "\tif len(boxes) > 0:\n",
        "\t\tnb_class = len(boxes[0].classes)\n",
        "\telse:\n",
        "\t\treturn\n",
        "\tfor c in range(nb_class):\n",
        "\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\t\tfor i in range(len(sorted_indices)):\n",
        "\t\t\tindex_i = sorted_indices[i]\n",
        "\t\t\tif boxes[index_i].classes[c] == 0: continue\n",
        "\t\t\tfor j in range(i+1, len(sorted_indices)):\n",
        "\t\t\t\tindex_j = sorted_indices[j]\n",
        "\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "\t\t\t\t\tboxes[index_j].classes[c] = 0\n",
        "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
        "\t\"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
        "\t\"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
        "\t\"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
        "\t\"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
        "\t\"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
        "\t\"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
        "\t\"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
        "\t\"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
        "\t\"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\",\"toothbrush\"] \n",
        "# load and prepare an image\n",
        "def load_image_pixels(filename, shape):\n",
        "\t# load the image to get its shape\n",
        "\t#image = load_img(filename)\n",
        "\twidth, height = image.size\n",
        "\tcv2.imread()\n",
        "\t# load the image with the required size\n",
        "\timage = load_img(filename, target_size=shape)\n",
        "\t# convert to numpy array\n",
        "\timage = img_to_array(image)\n",
        "\t# scale pixel values to [0, 1]\n",
        "\timage = image.astype('float32')\n",
        "\timage /= 255.0\n",
        "\t# add a dimension so that we have one sample\n",
        "\timage = expand_dims(image, 0)\n",
        "\treturn image, width, height\n",
        " \n",
        "# get all of the results above a threshold\n",
        "def get_boxes(boxes, labels, thresh):\n",
        "\tv_boxes, v_labels, v_scores = list(), list(), list()\n",
        "\t# enumerate all boxes\n",
        "\tfor box in boxes:\n",
        "\t\t# enumerate all possible labels\n",
        "\t\tfor i in range(len(labels)):\n",
        "\t\t\t# check if the threshold for this label is high enough\n",
        "\t\t\tif box.classes[i] > thresh:\n",
        "\t\t\t\tv_boxes.append(box)\n",
        "\t\t\t\tv_labels.append(labels[i])\n",
        "\t\t\t\tv_scores.append(box.classes[i]*100)\n",
        "\t\t\t\t# don't break, many labels may trigger for one box\n",
        "\treturn v_boxes, v_labels, v_scores\n",
        " \n",
        "# draw all results\n",
        "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
        "\t# load the image\n",
        "\tdata = pyplot.imread(filename)\n",
        "\t# plot the image\n",
        "\tpyplot.imshow(data)\n",
        "\t# get the context for drawing boxes\n",
        "\tax = pyplot.gca()\n",
        "\t# plot each box\n",
        "\tfor i in range(len(v_boxes)):\n",
        "\t\tbox = v_boxes[i]\n",
        "\t\t# get coordinates\n",
        "\t\ty1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "\t\t# calculate width and height of the box\n",
        "\t\twidth, height = x2 - x1, y2 - y1\n",
        "\t\t# create the shape\n",
        "\t\trect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
        "\t\t# draw the box\n",
        "\t\tax.add_patch(rect)\n",
        "\t\t# draw text and score in top left corner\n",
        "\t\tlabel = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
        "\t\tpyplot.text(x1, y1, label, color='white')\n",
        "\t# show the plot\n",
        "\tpyplot.show()\n",
        " "
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0fF_7rNcsFn",
        "colab_type": "text"
      },
      "source": [
        "* Below function returns True if an ambulance is found in an image else it returns False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbtQ3DJ1Ypiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def checkambulance(photo_filename):#PASS IMAGE PATH AS ARGUMENT\n",
        "  input_w, input_h = 416, 416\n",
        "  from keras.preprocessing.image import image\n",
        "  # load and prepare image\n",
        "  image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n",
        "  # make prediction\n",
        "  \n",
        "  yhat = modelyolo.predict(image)\n",
        "  anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
        "  class_threshold = 0.6\n",
        "  boxes = list()\n",
        "  for i in range(len(yhat)):\n",
        "    # decode the output of the network\n",
        "    boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n",
        "  # correct the sizes of the bounding boxes for the shape of the image\n",
        "  correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
        "  # suppress non-maximal boxes\n",
        "  do_nms(boxes, 0.5)\n",
        "  \n",
        "  # get the details of the detected objects\n",
        "  v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
        "  #im=io.imread(photo_filename)\n",
        "  for i in range(len(v_boxes)):\n",
        "    if(v_labels[i]=='truck' or v_labels[i]=='bus'):\n",
        "      box=v_boxes[i]\n",
        "      y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax      #EXTRACT CO-ORDINATES OF BOXES\n",
        "      width, height = x2 - x1, y2 - y1\n",
        "      if(height==0):\n",
        "        height=1\n",
        "      image1 =im[y1:y1+height,x1:x1+width]      #CROP BOX AND FEED TO ANOTHER MODEL\n",
        "      image1 = cv2.resize(image1,(224,224), interpolation = cv2.INTER_AREA)\n",
        "      img = np.expand_dims(image1, axis=0)\n",
        "      result=modelresnet.predict(img)\n",
        "      label = decode_predictions(result,top=15)\n",
        "      for i in range(15):\n",
        "        if(label[0][i][1]=='ambulance'):\n",
        "          plt.imshow(image1)\n",
        "          plt.show() \n",
        "          return True\n",
        "  return False"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGBXYgUndjwD",
        "colab_type": "text"
      },
      "source": [
        "Below code does the following\n",
        " *  Takes Frames from the videos provided\n",
        " *  Predicts the Traffic density for each Lane\n",
        " *  Amount of time for green signal will be given accordingly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPqJs9kAqZ7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_actual(a): ###actually our model returns 0 for light 1 for heavy and 2 for moderate\n",
        "  if a==0:        ###to convert it into a meaningful way we are swapping all the values and considering as follows:\n",
        "    return 2          ###   0 for light, 1 for moderate, 2 for heavy >>this is meaningful than the previous\n",
        "  if a==1:\n",
        "    return 0\n",
        "  if a==2:\n",
        "    return 1"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whfTRaplYvqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This code is commented because we were working in colab and colab doesn't support \n",
        "#         accessing the data from the database that is residing in our local laptop\n",
        "\n",
        "# This function will work if this code runs locally rather than on cloud\n",
        "\n",
        "# If all the lanes are heavy, then the below function adds to the database and notify users\n",
        "#                                                        regarding the heavy traffic at the signal junction\n",
        "'''def add_to_database(inname,indesc):\n",
        "  mydb = mysql.connector.connect(\n",
        "            host='127.0.0.1',\n",
        "            database='sitms',\n",
        "            user='root',\n",
        "            password='',\n",
        "            use_pure=True     \n",
        "            )\n",
        "  nowtime =str(datetime.now().time())\n",
        "  nowdate = str(datetime.now().date())\n",
        "  mycursor = mydb.cursor() \n",
        "  sql = \"INSERT INTO sitms_report_incident (incident_name,incident_desc,incident_date,incident_time,incident_location,incident_user) VALUES (%s, %s,%s,%s,%s,%s)\"\n",
        "  inplace='Signal Junction'\n",
        "  inuser='Traffic Signal'\n",
        "  val = inname,indesc,nowdate,nowtime,inplace,inuser\n",
        "  mycursor.execute(sql, val)\n",
        "  mydb.commit()'''\n",
        "\n",
        "# This class creates lane objects with a set of attributes (laneno, traffic_mode[high or medium or low], presence of ambulance[True or False])\n",
        "class Lane:\n",
        "  def __init__(self,laneno,traffic_mode,ambulance):\n",
        "    self.laneno=laneno\n",
        "    self.ambulance=ambulance\n",
        "    self.traffic_mode=traffic_mode\n",
        "class Traffic_manager:\n",
        "  @staticmethod\n",
        "  def return_priority(tensor):  # returns most prior lane. ex: if ambulance is present in a lane, then that is the most prior lane\n",
        "    for lane in tensor:\n",
        "      if lane.ambulance:\n",
        "        return lane\n",
        "    priority=max(tensor,key=lambda l:l.traffic_mode)\n",
        "    return priority\n",
        "\n",
        "  @staticmethod\n",
        "  def traffic_signal(lane,laneno,emergency=False):   # returns amount of time to be given for a given lane\n",
        "    if emergency:\n",
        "      print('green for lane'+str(laneno)+'due to emergency')\n",
        "      time.sleep(4)\n",
        "    else:\n",
        "      print('green for lane'+str(laneno),end=' ')\n",
        "      if lane.traffic_mode==0:\n",
        "        print('time alloted is 1sec','traffic mode is',lane.traffic_mode)\n",
        "        time.sleep(1)\n",
        "      if lane.traffic_mode==1:\n",
        "        print('time alloted is 3sec','traffic mode is',lane.traffic_mode)\n",
        "        time.sleep(3)\n",
        "      if lane.traffic_mode==2:\n",
        "        print('time alloted is 5sec','traffic mode is',lane.traffic_mode)\n",
        "        time.sleep(5)\n",
        "\n",
        "  @staticmethod\n",
        "  def cycle(tensor):\n",
        "    lanes=[i.laneno for i in tensor]\n",
        "    while tensor:\n",
        "      prior=Traffic_manager.return_priority(tensor)\n",
        "      arguments=[prior,prior.laneno,prior.ambulance==True]\n",
        "      signalthread=Thread(target=Traffic_manager.traffic_signal,args=arguments)\n",
        "      signalthread.start()    #here we are using threads so that CPU will be doing predictions for next instance while the traffic_signal func is in sleep\n",
        "      if(prior.ambulance==False):\n",
        "        tensor.remove(prior)\n",
        "        lanes.remove(prior.laneno)\n",
        "      \n",
        "      tensor=Traffic_manager.predictions(z)\n",
        "      tensor=[lane for lane in tensor if lane.laneno in lanes]\n",
        "      signalthread.join()\n",
        "\n",
        "  @staticmethod\n",
        "  def predictions(images):\n",
        "    p={}\n",
        "    for i in range(len(images)):\n",
        "      img=images[i]\n",
        "      outcome=list(Model.predict_classes(img))\n",
        "      outcome[0]=get_actual(outcome[0])\n",
        "      p[i]=outcome\n",
        "      check=False   #this is the output of check_ambulance function. \n",
        "      p[i]+=[check] #ex: p would be p={1:[high,false]},boolean represents presence of ambulance\n",
        "    array=[] #this array consists of Lane objects\n",
        "    for i in p:\n",
        "      array.append(Lane(i,p[i][0],p[i][1]))\n",
        "    return array\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLvtFyTqglY0",
        "colab_type": "text"
      },
      "source": [
        "**Below code is Driver code which takes 4 videos as input and gives specified time for each lane accordingly**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uIuo6fOYzdJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "1fce5e3c-c970-439e-9e9a-051b9e6b9c7a"
      },
      "source": [
        "import cv2\n",
        "v1=cv2.VideoCapture('/content/drive/My Drive/final video clips/VID_20200730_150201.mp4')\n",
        "# v2=cv2.VideoCapture('/content/drive/My Drive/final video clips/VID_20200730_151106.mp4')\n",
        "v3=cv2.VideoCapture('/content/drive/My Drive/final video clips/VID_20200730_151416.mp4')\n",
        "v4=cv2.VideoCapture('/content/drive/My Drive/final video clips/VID_20200730_151545.mp4')\n",
        "count=0\n",
        "s1,s2,s3,s4=[1,1,1,1]\n",
        "z=[]\n",
        "while s1 and s2  and s4:\n",
        "  s1,i1=v1.read()\n",
        "  # s2,i2=v2.read()\n",
        "  s3,i3=v3.read()\n",
        "  s4,i4=v4.read()\n",
        "  if count%50==0:   #50 defines that taking frame for every 50 frames\n",
        "    z=[i1,i3,i4]\n",
        "    for i in range(len(z)):\n",
        "      z[i]=np.resize(z[i],(224,224,3))\n",
        "      z[i]=np.expand_dims(z[i],axis=0)\n",
        "    result=Traffic_manager.predictions(z)\n",
        "    print(count//50,'th time')\n",
        "    Traffic_manager.cycle(result)\n",
        "  count+=1\n",
        "\n",
        "### Here we are interupting the while loop instead of going through entire video"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 th time\n",
            "green for lane0 time alloted is 1sec traffic mode is 0\n",
            "green for lane1 time alloted is 1sec traffic mode is 0\n",
            "green for lane2 time alloted is 1sec traffic mode is 0\n",
            "1 th time\n",
            "green for lane0 time alloted is 3sec traffic mode is 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-3ee1a0ef3c50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTraffic_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'th time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mTraffic_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m   \u001b[0mcount\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-6d3f561366f9>\u001b[0m in \u001b[0;36mcycle\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTraffic_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlane\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlane\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlane\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaneno\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlanes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m       \u001b[0msignalthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzKt405hsuAL",
        "colab_type": "text"
      },
      "source": [
        "# Please donot think that the upper block is an error.  We are just terminating the  infinite while loop instead of going through the entire video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QEh3XBUsNpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}